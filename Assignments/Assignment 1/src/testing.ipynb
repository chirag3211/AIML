{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Importing Libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import torch\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.image as img\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "import torch.nn.functional as F\n",
    "import numpy as np\n",
    "import os"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Data pre-processing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv('C:/Users/chira/Projects/AIML Lab/Assignments/Assignment 1/Assignment-1/input/train.csv')\n",
    "df1 = df.sample(frac = 1)\n",
    "df1.reset_index(inplace = True, drop = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_val_test_split(df, val_size, test_size):\n",
    "    val_size = int(len(df) * val_size)\n",
    "    test_size = int(len(df) * test_size)\n",
    "    train_data, val_data, test_data = df[test_size+val_size:], df[val_size:test_size+val_size], df[:test_size]\n",
    "    train_data.reset_index(inplace = True, drop = True)\n",
    "    val_data.reset_index(inplace = True, drop = True)\n",
    "    test_data.reset_index(inplace = True, drop = True)\n",
    "    return train_data, val_data, test_data\n",
    "\n",
    "def normalize(tensor):\n",
    "    mean = tensor.mean()\n",
    "    std = tensor.std()\n",
    "    return (tensor - mean) / std\n",
    "\n",
    "def getData(data, val_size, test_size):\n",
    "    train, val, test = train_val_test_split(data, val_size, test_size)\n",
    "    train_x = normalize(torch.from_numpy(train.iloc[:,1:].values.reshape(-1,1,28,28)).float())\n",
    "    train_y = torch.from_numpy(train.iloc[:,0].values.reshape(-1,1)).squeeze(1).long()\n",
    "    val_x = normalize(torch.from_numpy(val.iloc[:,1:].values.reshape(-1,1,28,28)).float())\n",
    "    val_y = torch.from_numpy(val.iloc[:,0].values.reshape(-1,1)).squeeze(1).long()\n",
    "    test_x = normalize(torch.from_numpy(test.iloc[:,1:].values.reshape(-1,1,28,28)).float())\n",
    "    test_y = torch.from_numpy(test.iloc[:,0].values.reshape(-1,1)).squeeze(1).long()\n",
    "    return train_x, train_y, val_x, val_y, test_x, test_y"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Model Architecture"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# switch to False to use CPU\n",
    "torch.cuda.is_available()\n",
    "use_cuda = False\n",
    "use_cuda = use_cuda and torch.cuda.is_available()\n",
    "device = torch.device(\"cuda\" if use_cuda else \"cpu\");\n",
    "torch.manual_seed(1);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Net(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(Net, self).__init__()\n",
    "        self.conv1 = nn.Conv2d(1, 10, kernel_size=5)\n",
    "        self.conv2 = nn.Conv2d(10, 20, kernel_size=5)\n",
    "        self.conv2_drop = nn.Dropout2d()\n",
    "        self.fc1 = nn.Linear(320, 160)\n",
    "        self.fc2 = nn.Linear(160, 80)\n",
    "        self.fc3 = nn.Linear(80, 40)\n",
    "        self.fc4 = nn.Linear(40, 10)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = F.relu(F.max_pool2d(self.conv1(x), 2))\n",
    "        x = F.relu(F.max_pool2d(self.conv2_drop(self.conv2(x)), 2))\n",
    "        x = x.view(-1, 320)\n",
    "        x = F.relu(self.fc1(x))\n",
    "        x = F.dropout(x, training=self.training)\n",
    "        x = F.relu(self.fc2(x))\n",
    "        x = F.dropout(x, training=self.training)\n",
    "        x = F.relu(self.fc3(x))\n",
    "        x = F.dropout(x, training=self.training)\n",
    "        x = self.fc4(x)\n",
    "        return x"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Early Stopping"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "class EarlyStopping:\n",
    "    def __init__(self, patience=7, verbose=False, delta=0):\n",
    "        self.patience = patience\n",
    "        self.verbose = verbose\n",
    "        self.counter = 0\n",
    "        self.best_score = None\n",
    "        self.early_stop = False\n",
    "        self.val_loss_min = np.Inf\n",
    "        self.delta = delta\n",
    "\n",
    "    def __call__(self, val_loss, model):\n",
    "        score = -val_loss\n",
    "        if self.best_score is None:\n",
    "            self.best_score = score\n",
    "            self.save_checkpoint(val_loss, model)\n",
    "        elif score < self.best_score + self.delta:\n",
    "            self.counter += 1\n",
    "            print(f'EarlyStopping counter: {self.counter} out of {self.patience}')\n",
    "            if self.counter >= self.patience:\n",
    "                self.early_stop = True\n",
    "        else:\n",
    "            self.best_score = score\n",
    "            self.save_checkpoint(val_loss, model)\n",
    "            self.counter = 0\n",
    "\n",
    "    def save_checkpoint(self, val_loss, model):\n",
    "        if self.verbose:\n",
    "            print(f'Validation loss decreased ({self.val_loss_min:.6f} --> {val_loss:.6f}).  Saving model ...')\n",
    "        torch.save(model.state_dict(), 'C:/Users/chira/Projects/AIML Lab/Assignments/Assignment 1/Assignment-1/model/model.pt')\n",
    "        self.val_loss_min = val_loss"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train(model, device, x_train, t_train, x_val, t_val, optimizer, epoch):\n",
    "    model.train()\n",
    "    \n",
    "    for start in range(0, len(t_train)-1, 256):\n",
    "        end = start + 256\n",
    "        x, y = x_train[start:end], t_train[start:end]\n",
    "        x, y = x.to(device), y.to(device)\n",
    "        \n",
    "        optimizer.zero_grad()\n",
    "\n",
    "        output = model(x)\n",
    "        loss = F.cross_entropy(output, y)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "    # Training accuracy calculation\n",
    "    _, train_accuracy = test(model, device, x_train, t_train, batch_size=256, mode=\"train\")\n",
    "\n",
    "    # Validation loss and accuracy calculation\n",
    "    val_loss, val_accuracy = test(model, device, x_val, t_val, batch_size=256, mode=\"val\")\n",
    "\n",
    "    print('Epoch: {} \\tTraining Loss: {:.6f} \\tTraining Accuracy: {:.2f}% \\tValidation Loss: {:.4f} \\tValidation Accuracy: {:.2f}%'.format(epoch, loss.item(), train_accuracy, val_loss, val_accuracy))\n",
    "    return loss.item(), train_accuracy, val_loss, val_accuracy\n",
    "\n",
    "def test(model, device, x_data, t_data, batch_size, mode=\"test\"):\n",
    "    model.eval()\n",
    "    data_size = len(t_data)\n",
    "    total_loss = 0\n",
    "    correct = 0\n",
    "\n",
    "    for start in range(0, data_size-1, batch_size):\n",
    "        end = start + batch_size\n",
    "        with torch.no_grad():\n",
    "            x, y = x_data[start:end], t_data[start:end]\n",
    "            x, y = x.to(device), y.to(device)\n",
    "            output = model(x)\n",
    "            total_loss += F.cross_entropy(output, y).item() # sum up batch loss\n",
    "            pred = output.max(1, keepdim=True)[1] # get the index of the max logit\n",
    "            correct += pred.eq(y.view_as(pred)).sum().item()\n",
    "\n",
    "    total_loss /= len(t_data)\n",
    "    accuracy = 100. * correct / len(t_data)\n",
    "    if mode == 'test':\n",
    "      print('{} set: Average loss: {:.4f}, Accuracy: {}/{} ({:.2f}%)'.format(\n",
    "          mode.capitalize(), total_loss, correct, len(t_data), accuracy))\n",
    "\n",
    "    return total_loss, accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 1 \tTraining Loss: 0.422490 \tTraining Accuracy: 94.32% \tValidation Loss: 0.0010 \tValidation Accuracy: 94.07%\n",
      "Validation loss decreased (inf --> 0.000954).  Saving model ...\n",
      "Epoch: 2 \tTraining Loss: 0.170231 \tTraining Accuracy: 96.74% \tValidation Loss: 0.0005 \tValidation Accuracy: 96.29%\n",
      "Validation loss decreased (0.000954 --> 0.000539).  Saving model ...\n",
      "Epoch: 3 \tTraining Loss: 0.236740 \tTraining Accuracy: 97.09% \tValidation Loss: 0.0005 \tValidation Accuracy: 96.62%\n",
      "Validation loss decreased (0.000539 --> 0.000482).  Saving model ...\n",
      "Epoch: 4 \tTraining Loss: 0.087504 \tTraining Accuracy: 97.75% \tValidation Loss: 0.0004 \tValidation Accuracy: 97.60%\n",
      "Validation loss decreased (0.000482 --> 0.000391).  Saving model ...\n",
      "Epoch: 5 \tTraining Loss: 0.099783 \tTraining Accuracy: 98.11% \tValidation Loss: 0.0004 \tValidation Accuracy: 97.83%\n",
      "Validation loss decreased (0.000391 --> 0.000350).  Saving model ...\n",
      "Epoch: 6 \tTraining Loss: 0.106465 \tTraining Accuracy: 98.10% \tValidation Loss: 0.0003 \tValidation Accuracy: 97.90%\n",
      "Validation loss decreased (0.000350 --> 0.000336).  Saving model ...\n",
      "Epoch: 7 \tTraining Loss: 0.257386 \tTraining Accuracy: 98.46% \tValidation Loss: 0.0003 \tValidation Accuracy: 98.31%\n",
      "Validation loss decreased (0.000336 --> 0.000308).  Saving model ...\n",
      "Epoch: 8 \tTraining Loss: 0.194024 \tTraining Accuracy: 98.42% \tValidation Loss: 0.0003 \tValidation Accuracy: 98.17%\n",
      "EarlyStopping counter: 1 out of 4\n",
      "Epoch: 9 \tTraining Loss: 0.188957 \tTraining Accuracy: 98.47% \tValidation Loss: 0.0003 \tValidation Accuracy: 98.10%\n",
      "Validation loss decreased (0.000308 --> 0.000290).  Saving model ...\n",
      "Epoch: 10 \tTraining Loss: 0.039463 \tTraining Accuracy: 98.46% \tValidation Loss: 0.0003 \tValidation Accuracy: 98.26%\n",
      "EarlyStopping counter: 1 out of 4\n",
      "Epoch: 11 \tTraining Loss: 0.087596 \tTraining Accuracy: 98.69% \tValidation Loss: 0.0003 \tValidation Accuracy: 98.43%\n",
      "Validation loss decreased (0.000290 --> 0.000271).  Saving model ...\n",
      "Epoch: 12 \tTraining Loss: 0.077079 \tTraining Accuracy: 98.85% \tValidation Loss: 0.0002 \tValidation Accuracy: 98.50%\n",
      "Validation loss decreased (0.000271 --> 0.000249).  Saving model ...\n",
      "Epoch: 13 \tTraining Loss: 0.050410 \tTraining Accuracy: 98.76% \tValidation Loss: 0.0003 \tValidation Accuracy: 98.43%\n",
      "EarlyStopping counter: 1 out of 4\n",
      "Epoch: 14 \tTraining Loss: 0.090857 \tTraining Accuracy: 98.86% \tValidation Loss: 0.0002 \tValidation Accuracy: 98.52%\n",
      "Validation loss decreased (0.000249 --> 0.000248).  Saving model ...\n",
      "Epoch: 15 \tTraining Loss: 0.054890 \tTraining Accuracy: 98.88% \tValidation Loss: 0.0003 \tValidation Accuracy: 98.45%\n",
      "EarlyStopping counter: 1 out of 4\n",
      "Epoch: 16 \tTraining Loss: 0.092567 \tTraining Accuracy: 98.88% \tValidation Loss: 0.0002 \tValidation Accuracy: 98.52%\n",
      "Validation loss decreased (0.000248 --> 0.000228).  Saving model ...\n",
      "Epoch: 17 \tTraining Loss: 0.076137 \tTraining Accuracy: 98.97% \tValidation Loss: 0.0002 \tValidation Accuracy: 98.67%\n",
      "Validation loss decreased (0.000228 --> 0.000212).  Saving model ...\n",
      "Epoch: 18 \tTraining Loss: 0.134181 \tTraining Accuracy: 99.01% \tValidation Loss: 0.0002 \tValidation Accuracy: 98.74%\n",
      "EarlyStopping counter: 1 out of 4\n",
      "Epoch: 19 \tTraining Loss: 0.177718 \tTraining Accuracy: 99.03% \tValidation Loss: 0.0002 \tValidation Accuracy: 98.48%\n",
      "EarlyStopping counter: 2 out of 4\n",
      "Epoch: 20 \tTraining Loss: 0.071366 \tTraining Accuracy: 99.05% \tValidation Loss: 0.0002 \tValidation Accuracy: 98.69%\n",
      "Validation loss decreased (0.000212 --> 0.000210).  Saving model ...\n",
      "Epoch: 21 \tTraining Loss: 0.175835 \tTraining Accuracy: 99.17% \tValidation Loss: 0.0002 \tValidation Accuracy: 98.79%\n",
      "Validation loss decreased (0.000210 --> 0.000196).  Saving model ...\n",
      "Epoch: 22 \tTraining Loss: 0.080152 \tTraining Accuracy: 99.18% \tValidation Loss: 0.0002 \tValidation Accuracy: 98.76%\n",
      "EarlyStopping counter: 1 out of 4\n",
      "Epoch: 23 \tTraining Loss: 0.031500 \tTraining Accuracy: 99.14% \tValidation Loss: 0.0002 \tValidation Accuracy: 98.62%\n",
      "EarlyStopping counter: 2 out of 4\n",
      "Epoch: 24 \tTraining Loss: 0.057901 \tTraining Accuracy: 99.12% \tValidation Loss: 0.0002 \tValidation Accuracy: 98.64%\n",
      "EarlyStopping counter: 3 out of 4\n",
      "Epoch: 25 \tTraining Loss: 0.099395 \tTraining Accuracy: 99.16% \tValidation Loss: 0.0002 \tValidation Accuracy: 98.90%\n",
      "EarlyStopping counter: 4 out of 4\n",
      "Early stopping\n",
      "Test set: Average loss: 0.0002, Accuracy: 4141/4200 (98.60%)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(0.0002415250184103137, 98.5952380952381)"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model = Net().to(device)\n",
    "optimizer = optim.Adam(model.parameters(), lr=0.002)\n",
    "early_stopping = EarlyStopping(patience=4, verbose=True)\n",
    "train_x, train_y, val_x, val_y, test_x, test_y = getData(df1, val_size = 0.1, test_size = 0.1)\n",
    "epochs = 40\n",
    "for epoch in range(1, epochs + 1):\n",
    "  _, _, val_loss, _ = train(model, device, train_x, train_y, val_x, val_y, optimizer, epoch)\n",
    "  early_stopping(val_loss, model)\n",
    "  if early_stopping.early_stop:\n",
    "    print(\"Early stopping\")\n",
    "    break\n",
    "test(model, device, test_x, test_y, batch_size=256)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Handling of test_images"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\chira\\AppData\\Local\\Temp\\ipykernel_30512\\2509342156.py:2: UserWarning: The given NumPy array is not writable, and PyTorch does not support non-writable tensors. This means writing to this tensor will result in undefined behavior. You may want to copy the array to protect its data or make it writable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at C:\\actions-runner\\_work\\pytorch\\pytorch\\builder\\windows\\pytorch\\torch\\csrc\\utils\\tensor_numpy.cpp:212.)\n",
      "  plt.imshow(torch.from_numpy(img.imread('C:/Users/chira/Projects/AIML Lab/Assignments/Assignment 1/Assignment-1/test_images/img_{}.jpg'.format(i+1))))\n"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "for i in range(10):\n",
    "    plt.imshow(torch.from_numpy(img.imread('C:/Users/chira/Projects/AIML Lab/Assignments/Assignment 1/Assignment-1/test_images/img_{}.jpg'.format(i+1))))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "AIML",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
